{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = T, eval = T, message = F, warning = F, error = F, comment = NA, cache = F, include = T, R.options = list(width = 100), collapse = T, dpi = 200, fig.align = \"center\", fig.height = 5, fig.width = 8)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The homeworks are not graded, but the results may be sent to tommaso.rigon@unimib.it to receive feedbacks. \n",
                "\n",
                "## Introduction\n",
                "\n",
                "In this homework we consider the **CAGE cancer dataset** that is described in the tutorial [**genes_tutorial.md**](https://github.com/danieledurante/ProbitSUN/blob/master/genes_tutorial.md). This is the same dataset  that is presented in the article [Durante (2019), *Conjugate Bayes for Probit Regression via Unified Skew-Normal Distributions*](https://academic.oup.com/biomet/article/106/4/765/5554418). \n",
                "\n",
                "\n",
                "**Note**. This is a high-dimensional problem, so adjust your expectations about the performance of the algorithms accordingly. \n",
                "\n",
                "### Dataset description (from the `gene_tutorial.md` document)\n",
                "\n",
                "The focus is on learning how gene expression (monitored at $p - 1 = 516$ tags) relates to the probability of a cancerous tissue. Data are available for $n = 74$ measurements and can be downloaded at Cancer SAGE by clicking [here](http://www.i3s.unice.fr/~pasquier/web/userfiles/downloads/datasets/SAGE_filtered_small_dataset.zip). The download provides a directory `SAGE_filtered_small_dataset` which contains several datasets. Here the focus is on `dataset_74-516.csv`. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rm(list = ls())\n",
                "dataset_gene <- read.csv(\"dataset_74-516.csv\", header = TRUE, sep = \"\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The dataframe  `dataset_gene` contains information on the **response variable** (first column of `dataset_gene`), and on the **covariates** (subsequent columns of `dataset_gene`). More specifically, the first column `dataset_gene[, 1]` contains names of tissues followed by a letter which is either *N* (normal) or *C* (cancerous). Exploiting this information, **let us create the response by hand**.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_data <- c(\n",
                "  0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
                "  1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
                "  0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The design matrix comprising the covariates can be easily obtained by extracting the remaining columns in `dataset_gene`. Following [Gelman et al. (2008)](https://projecteuclid.org/euclid.aoas/1231424214), **such covariates are also rescaled and an intercept term is added**.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_data <- cbind(1, scale(dataset_gene[, -1]))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Homework\n",
                "\n",
                "### Model description\n",
                "\n",
                "Let $\\textbf{y} = (y_1,\\dots,y_n)^\\intercal$ be the vector of the observed **binary responses** (variable `y_data`) and let $\\textbf{X}$ be the corresponding **design matrix** (object `X_data`) whose generic row is $\\textbf{x}_i = (x_{i1},\\dots,x_{ip})^\\intercal$, for $i=1,\\dots,n$, suitably standardized. Consider a generalized linear model such that\n",
                "\n",
                "$$\n",
                "y_i \\mid \\pi_i \\overset{\\text{ind}}{\\sim} \\text{Bern}(\\pi_i), \\qquad \\pi_i = g(\\eta_i), \\qquad \\eta_i = \\beta_1x_{i1} + \\cdots + \\beta_p x_{ip},\n",
                "$$\n",
                "where $g(\\cdot)$ is the **probit link** (`pnorm` function) and let the **prior** be $\\beta \\sim N(0, 16 I_p)$.  \n",
                "\n",
                "### Assignments\n",
                "\n",
                "1. Implement a **random walk Metropolis** algorithm for sampling from the posterior distribution of $\\beta$. Tune the covariance matrix of the Gaussian proposal distribution by trial and error. \n",
                "\n",
                "1. Obtain a rough estimate of the posterior covariance matrix using the Laplace approximation; refer to [Chopin & Ridgway (2017)](https://projecteuclid.org/journals/statistical-science/volume-32/issue-1/Leave-Pima-Indians-Alone--Binary-Regression-as-a-Benchmark/10.1214/16-STS581.full) for the details. Then, run a **random walk Metropolis** based on this approximation. \n",
                "\n",
                "1. Implement a **MALA** algorithm for the sampling from the posterior distribution of $\\beta$ based approximation for the covariance matrix obtained in the previous point.\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
