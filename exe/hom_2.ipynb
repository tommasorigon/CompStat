{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = T, eval = T, message = F, warning = F, error = F, comment = NA, cache = F, include = T, R.options = list(width = 100), collapse = T, dpi = 200, fig.align = \"center\", fig.height = 5, fig.width = 8)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The homeworks are not graded, but the results may be sent to tommaso.rigon@unimib.it to receive feedbacks. \n",
                "\n",
                "## Pima indian dataset\n",
                "\n",
                "In this homework we consider once again the **Pima indian dataset**, as in the previous [**Markdown document B.1**](un_B1.html). Importantly, note that in this homework we will **not standardize the predictors** to make the computational problem more challenging. \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Pima <- rbind(MASS::Pima.tr, MASS::Pima.te)\n",
                "y <- as.numeric(Pima$type == \"Yes\") # Binary outcome\n",
                "X <- cbind(1, model.matrix(type ~ . - 1, data = Pima)) # Design matrix\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Homework\n",
                "\n",
                "### Model description\n",
                "\n",
                "Let $\\textbf{y} = (y_1,\\dots,y_n)^\\intercal$ be the vector of the observed **binary responses** (variable `y_data`) and let $\\textbf{X}$ be the corresponding **design matrix** (object `X_data`) whose generic row is $\\textbf{x}_i = (x_{i1},\\dots,x_{ip})^\\intercal$, for $i=1,\\dots,n$, suitably standardized. Consider a generalized linear model such that\n",
                "\n",
                "$$\n",
                "y_i \\mid \\pi_i \\overset{\\text{ind}}{\\sim} \\text{Bern}(\\pi_i), \\qquad \\pi_i = \\Phi(\\eta_i), \\qquad \\eta_i = \\beta_1x_{i1} + \\cdots + \\beta_p x_{ip},\n",
                "$$\n",
                "where $\\Phi(\\cdot)$ is the **probit link** (`pnorm` function).As done in [**Markdown document B.1**](un_B1.html), we will employ a relatively vague prior centered at $0$, namely $\\beta \\sim N(0, 100 I_p)$. \n",
                "\n",
                "### Assignments\n",
                "\n",
                "1. Implement the **Albert and Chib (1993)** data augmentation algorithm for sampling from the posterior distribution of $\\beta$. \n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
