{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/tommasorigon/CompStat/blob/main/notebook/hom_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"tnQ0Z8TAr95X"},"source":["# Homework 1\n"]},{"cell_type":"markdown","metadata":{"id":"z_LidUHur95h"},"source":["The homeworks are not graded, but the results may be sent to tommaso.rigon@unimib.it to receive feedbacks. \n","\n","## Introduction\n","\n","In this homework we consider the **CAGE cancer dataset** that is described in the tutorial [**genes_tutorial.md**](https://github.com/danieledurante/ProbitSUN/blob/master/genes_tutorial.md). This is the same dataset  that is presented in the article [Durante (2019), *Conjugate Bayes for Probit Regression via Unified Skew-Normal Distributions*](https://academic.oup.com/biomet/article/106/4/765/5554418). \n","\n","\n","**Note**. This is a high-dimensional problem, so adjust your expectations about the performance of the algorithms accordingly. \n","\n","### Dataset description (from the `gene_tutorial.md` document)\n","\n","The focus is on learning how gene expression (monitored at $p - 1 = 516$ tags) relates to the probability of a cancerous tissue. Data are available for $n = 74$ measurements and can be downloaded at Cancer SAGE by clicking [here](http://www.i3s.unice.fr/~pasquier/web/userfiles/downloads/datasets/SAGE_filtered_small_dataset.zip). The download provides a directory `SAGE_filtered_small_dataset` which contains several datasets. Here the focus is on `dataset_74-516.csv`. \n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"cUZA0Bjhr95i","executionInfo":{"status":"ok","timestamp":1646411920526,"user_tz":-60,"elapsed":941,"user":{"displayName":"Tommaso Rigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipIA-GFbSE02GMALk8dwNJgy36LN8CARkkbRTFdjg=s64","userId":"15611440935089428693"}}},"outputs":[],"source":["rm(list = ls())\n","dataset_gene <- read.csv(\"http://tommasorigon.github.io/CompStat/notebook/dataset_74-516.csv\", header = TRUE, sep = \"\")"]},{"cell_type":"markdown","metadata":{"id":"o9dE0aM1r95j"},"source":["The dataframe  `dataset_gene` contains information on the **response variable** (first column of `dataset_gene`), and on the **covariates** (subsequent columns of `dataset_gene`). More specifically, the first column `dataset_gene[, 1]` contains names of tissues followed by a letter which is either *N* (normal) or *C* (cancerous). Exploiting this information, **let us create the response by hand**.\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"W68K5E9ir95j","executionInfo":{"status":"ok","timestamp":1646411924099,"user_tz":-60,"elapsed":245,"user":{"displayName":"Tommaso Rigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipIA-GFbSE02GMALk8dwNJgy36LN8CARkkbRTFdjg=s64","userId":"15611440935089428693"}}},"outputs":[],"source":["y_data <- c(\n","  0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","  1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n","  0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1\n",")"]},{"cell_type":"markdown","metadata":{"id":"Mg-GZzjIr95k"},"source":["The design matrix comprising the covariates can be easily obtained by extracting the remaining columns in `dataset_gene`. Following [Gelman et al. (2008)](https://projecteuclid.org/euclid.aoas/1231424214), **such covariates are also rescaled and an intercept term is added**.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xExxCYMUr95l","executionInfo":{"status":"ok","timestamp":1646411928592,"user_tz":-60,"elapsed":242,"user":{"displayName":"Tommaso Rigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GipIA-GFbSE02GMALk8dwNJgy36LN8CARkkbRTFdjg=s64","userId":"15611440935089428693"}}},"outputs":[],"source":["X_data <- cbind(1, scale(dataset_gene[, -1]))"]},{"cell_type":"markdown","metadata":{"id":"tc1sOaPLr95l"},"source":["## Homework\n","\n","### Model description\n","\n","Let $\\textbf{y} = (y_1,\\dots,y_n)^\\intercal$ be the vector of the observed **binary responses** (variable `y_data`) and let $\\textbf{X}$ be the corresponding **design matrix** (object `X_data`) whose generic row is $\\textbf{x}_i = (x_{i1},\\dots,x_{ip})^\\intercal$, for $i=1,\\dots,n$, suitably standardized. Consider a generalized linear model such that\n","\n","$$\n","y_i \\mid \\pi_i \\overset{\\text{ind}}{\\sim} \\text{Bern}(\\pi_i), \\qquad \\pi_i = g(\\eta_i), \\qquad \\eta_i = \\beta_1x_{i1} + \\cdots + \\beta_p x_{ip},\n","$$\n","where $g(\\cdot)$ is the **probit link** (`pnorm` function) and let the **prior** be $\\beta \\sim N(0, 16 I_p)$.  \n","\n","### Assignments\n","\n","1. Implement a **random walk Metropolis** algorithm for sampling from the posterior distribution of $\\beta$. Tune the covariance matrix of the Gaussian proposal distribution by trial and error. \n","\n","1. Obtain a rough estimate of the posterior covariance matrix using the Laplace approximation; refer to [Chopin & Ridgway (2017)](https://projecteuclid.org/journals/statistical-science/volume-32/issue-1/Leave-Pima-Indians-Alone--Binary-Regression-as-a-Benchmark/10.1214/16-STS581.full) for the details. Then, run a **random walk Metropolis** based on this approximation. \n","\n","1. Implement a **MALA** algorithm for the sampling from the posterior distribution of $\\beta$ based approximation for the covariance matrix obtained in the previous point.\n"]}],"metadata":{"anaconda-cloud":"","kernelspec":{"display_name":"R","langauge":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.1"},"colab":{"name":"hom_1.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}