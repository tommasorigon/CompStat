{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/tommasorigon/CompStat/blob/main/notebook/hom_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"e_GXDv0AsWSm"},"source":["# Homework 2\n"]},{"cell_type":"markdown","metadata":{"id":"NQeb9DedsWSw"},"source":["The homeworks are not graded, but the results may be sent to tommaso.rigon@unimib.it to receive feedbacks. \n","\n","## Pima indian dataset\n","\n","In this homework we consider once again the **Pima indian dataset**, as in the previous [**Notebook B.1**](https://colab.research.google.com/github/tommasorigon/CompStat/blob/main/notebook/un_B1.ipynb). Importantly, note that in this homework we will **not standardize the predictors** to make the computational problem more challenging. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_zid85lsWSw"},"outputs":[],"source":["Pima <- rbind(MASS::Pima.tr, MASS::Pima.te)\n","y <- as.numeric(Pima$type == \"Yes\") # Binary outcome\n","X <- cbind(1, model.matrix(type ~ . - 1, data = Pima)) # Design matrix"]},{"cell_type":"markdown","metadata":{"id":"Y2B23zQssWSx"},"source":["## Homework\n","\n","### Model description\n","\n","Let $\\textbf{y} = (y_1,\\dots,y_n)^\\intercal$ be the vector of the observed **binary responses** (variable `y_data`) and let $\\textbf{X}$ be the corresponding **design matrix** (object `X_data`) whose generic row is $\\textbf{x}_i = (x_{i1},\\dots,x_{ip})^\\intercal$, for $i=1,\\dots,n$, suitably standardized. Consider a generalized linear model such that\n","\n","$$\n","y_i \\mid \\pi_i \\overset{\\text{ind}}{\\sim} \\text{Bern}(\\pi_i), \\qquad \\pi_i = \\Phi(\\eta_i), \\qquad \\eta_i = \\beta_1x_{i1} + \\cdots + \\beta_p x_{ip},\n","$$\n","where $\\Phi(\\cdot)$ is the **probit link** (`pnorm` function). As done in the  [**Notebook B.1**](https://colab.research.google.com/github/tommasorigon/CompStat/blob/main/notebook/un_B1.ipynb), we will employ a relatively vague prior centered at $0$, namely $\\beta \\sim N(0, 100 I_p)$. \n","\n","### Assignments\n","\n","1. Implement the **Albert and Chib (1993)** data augmentation algorithm for sampling from the posterior distribution of $\\beta$. \n"]},{"cell_type":"code","source":[""],"metadata":{"id":"Sv432k043jME"},"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":"","kernelspec":{"display_name":"R","langauge":"R","name":"ir"},"language_info":{"codemirror_mode":"r","file_extension":".r","mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.1"},"colab":{"name":"hom_2.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}