{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tommasorigon/CompStat/blob/main/notebook/un_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1Rd-Z_qOhVi"
   },
   "source": [
    "## Unit A.1 - R programming and MCMC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - Autoregressive processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code allows to simulate from an autoregressive process. Autoregressive processes provide a simple illustration of **Markov chains** on continuous state-space.\n",
    "\n",
    "Let $Y^{(0)} \\sim N(10, 1)$ and let us define\n",
    "\n",
    "$$\n",
    "Y^{(r)} = \\rho Y^{(r-1)} + \\epsilon^{(r)}, \\qquad \\phi \\in \\mathbb{R},\n",
    "$$\n",
    "\n",
    "with the error terms $\\epsilon^{(r)}$ being iid according to a standard Gaussian $\\text{N}(0,1)$. \n",
    "\n",
    "Then the sequence of $Y^{(r)}$ forms indeed a Markov chain and the **transition density** is such that\n",
    "\n",
    "$$\n",
    "(y^{(r)} \\mid y^{(r-1)})  \\sim \\text{N}(\\rho y^{(r-1)}, 1).\n",
    "$$ \n",
    "\n",
    "If the parameter $|\\rho| < 1$ then the Markov chain has a more \"**stable**\" behaviour (i.e. the process is stationary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R <- 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stationary process\n",
    "set.seed(123)\n",
    "rho <- 0.5\n",
    "y_stat <- numeric(R + 1)\n",
    "y_stat[1] <- rnorm(1, 30, 1)\n",
    "for(r in 1:R){\n",
    "    y_stat[r + 1] = rho * y_stat[r] + rnorm(1)\n",
    "}\n",
    "\n",
    "plot(y_stat, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-stationary process\n",
    "set.seed(123)\n",
    "rho <- 1\n",
    "y_nstat <- numeric(R + 1)\n",
    "y_nstat[1] <- rnorm(1, 100, 1)\n",
    "for(r in 1:R){\n",
    "    y_nstat[r + 1] = rho * y_nstat[r] + rnorm(1)\n",
    "}\n",
    "plot(y_nstat, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a pdf file\n",
    "pdf(\"autoregressive.pdf\", width = 10, height = 6) \n",
    "par(mfrow = c(1,2))\n",
    "plot(y_stat, type = \"l\")\n",
    "plot(y_nstat, type = \"l\")\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wish to simulate from a Gaussian distribution $\\text{N}(\\mu, \\sigma^2)$ using a MH algorithm, whose density is $\\pi(y)$.\n",
    "\n",
    "This is obviously a **toy example**, because in practice one would just use `rnorm`.  For the proposal distribution $q(y^* \\mid y)$, we can use a **uniform random walk**, namely\n",
    "$$\n",
    "y^* = y + u, \\qquad u \\sim \\text{Unif}(-\\epsilon, \\epsilon).\n",
    "$$\n",
    "The choice of $\\epsilon > 0$ will have an impact on the algorithm, as we shall see.\n",
    "\n",
    "Random walks are **symmetric** proposals distributions, so $q(y^* \\mid y) = q(y \\mid y^*)$. This means the acceptance probability $\\alpha$ is equal to\n",
    "$$\n",
    "\\alpha(y^*, y) = \\min\\left\\{1, \\frac{\\pi(y^*)} {\\pi(y)}\\right\\}.\n",
    "$$\n",
    "\n",
    "The implementation in **R** for a generic Gaussian with mean `mu` and standard deviation `sig` is the following code. Morerover, here `x0` is the starting value and `ep` corresponds to $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mcmc <- function(R, mu, sig, ep, x0) {\n",
    "    \n",
    "    # Initialization\n",
    "    out <- numeric(R + 1)\n",
    "    out[1] <- x0\n",
    "    \n",
    "    # Beginning of the chain\n",
    "    x <- x0\n",
    "    # Metropolis algorithm\n",
    "    for(r in 1:R){\n",
    "        # Proposed values\n",
    "        xs     <- x + runif(1, -ep, ep)\n",
    "        # Acceptance probability\n",
    "        alpha  <- min(dnorm(xs, mu, sig) / dnorm(x, mu, sig), 1)\n",
    "        # Acceptance / rejection step\n",
    "        accept <- rbinom(1, size = 1, prob = alpha)\n",
    "    \n",
    "        if(accept == 1) {\n",
    "            x <- xs\n",
    "        }\n",
    "        out[r + 1] <- x\n",
    "    }\n",
    "    out \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(2, 2))\n",
    "\n",
    "set.seed(123)\n",
    "sim1 <- norm_mcmc(1000, mu = 2, sig = 5, ep = 100, x0 = 50)\n",
    "plot(sim1, type = \"l\")\n",
    "\n",
    "sim2 <- norm_mcmc(1000, mu = 2, sig = 5, ep = 50, x0 = 50)\n",
    "plot(sim2, type = \"l\")\n",
    "\n",
    "sim3 <- norm_mcmc(1000, mu = 2, sig = 5, ep = 10, x0 = 50)\n",
    "plot(sim3, type = \"l\")\n",
    "\n",
    "sim4 <- norm_mcmc(1000, mu = 2, sig = 5, ep = 1, x0 = 50)\n",
    "plot(sim4, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(\"traceplot_gauss.pdf\", width = 10, height = 6) \n",
    "par(mfrow = c(2,2))\n",
    "plot(sim1, type = \"l\", main = \"ep = 100\", ylab = \"y\", xlab = \"iteration\")\n",
    "plot(sim2, type = \"l\", main = \"ep = 50\", ylab = \"y\", xlab = \"iteration\")\n",
    "plot(sim3, type = \"l\", main = \"ep = 10\", ylab = \"y\", xlab = \"iteration\")\n",
    "plot(sim4, type = \"l\", main = \"ep = 1\", ylab = \"y\", xlab = \"iteration\")\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow = c(2, 2))\n",
    "acf(sim1)\n",
    "acf(sim2)\n",
    "acf(sim3)\n",
    "acf(sim4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(\"auto_gauss.pdf\", width = 10, height = 6) \n",
    "par(mfrow = c(2,2))\n",
    "acf(sim1)\n",
    "acf(sim2)\n",
    "acf(sim3)\n",
    "acf(sim4)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose `ep = 10`, namely the value that guarantee a good (low) auto-correlation. We now simulate a longer chain, which is compared with the nominal distribution, having omitted the burn-in period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the MH chain\n",
    "sim <- norm_mcmc(50000, mu = 2, sig = 5, ep = 10, x0 = 50)\n",
    "\n",
    "# Identify a burn-in period\n",
    "burn_in <- 1:200\n",
    "sim <- sim[-c(burn_in)]\n",
    "# Plot the results\n",
    "hist(sim, breaks = 100, freq = FALSE)\n",
    "curve(dnorm(x, 2, 5), add = T) # This is usually not known!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(\"sim_gauss.pdf\", width = 10, height = 6) \n",
    "hist(sim, breaks = 100, freq = FALSE)\n",
    "curve(dnorm(x, 2, 5), add = T) # This is usually not known!\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(\"auto_gauss.pdf\", width = 10, height = 6) \n",
    "par(mfrow = c(2,2))\n",
    "acf(sim1)\n",
    "acf(sim2)\n",
    "acf(sim3)\n",
    "acf(sim4)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYBqP0PlOhVo"
   },
   "source": [
    "## The `hearth` dataset\n",
    "\n",
    "In the following it is described an implementation of a **random walk Metropolis-Hastings** algorithm for a Weibull survival model. Please refer to the [**slides of the unit A.1**](../slides/un_A1.pdf) for a more complete description of the algorithm and the model itself. \n",
    "\n",
    "\n",
    "In first place, let us load the `stanford2` dataset, which is available in the `survival` R package. As described in the documentation, this dataset includes:\n",
    "\n",
    "> Survival of patients on the waiting list for the Stanford heart transplant program.\n",
    "\n",
    "See also the documentation of the `hearth` dataset for a more complete description. The survival times are saved in the `time` variable which can be either **complete** (`status = 1`) or **censored** (`status = 0`). \n",
    "\n",
    "Let $\\textbf{t} = (t_1,\\dots,t_n)^\\intercal$ be the vector of the observed survival times and let $\\textbf{d} = (d_1,\\dots,d_n)^\\intercal$ be the corresponding binary vector of censorship statuses. We load in **R** these quantities and we obtain the **Kaplan-Meier** estimate of the survival function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "urOM_swTOhVp",
    "outputId": "98fc26f2-b4de-4dab-da67-533b72972648"
   },
   "outputs": [],
   "source": [
    "library(survival)\n",
    "t <- stanford2$time # Survival times\n",
    "d <- stanford2$status # Censorship indicator\n",
    "\n",
    "# Kaplan-Meier estimate\n",
    "fit_KM <- survfit(Surv(t, d) ~ 1)\n",
    "plot(fit_KM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCjgAGC1OhVp"
   },
   "source": [
    "### Weibull model and likelihood function\n",
    "\n",
    "We are interested in fitting a Bayesian model for estimating the survival function and quantify the associated uncertainty. A common parametric model for survival data is the **Weibull** model, which has the following density, hazard and survival functions\n",
    "\n",
    "$$\n",
    "f(t \\mid \\alpha, \\beta) = \\frac{\\alpha}{\\beta}\\left(\\frac{t}{\\beta}\\right)^{\\alpha - 1}\\exp\\left\\{- \\left(\\frac{t}{\\beta}\\right)^{\\alpha}\\right\\},\n",
    "\\quad h(t \\mid \\alpha, \\beta) = \\frac{\\alpha}{\\beta}\\left(\\frac{t}{\\beta}\\right)^{\\alpha - 1},\n",
    "\\quad S(t \\mid \\alpha, \\beta) = \\exp\\left\\{- \\left(\\frac{t}{\\beta}\\right)^{\\alpha}\\right\\}. \n",
    "$$\n",
    "The likelihood for this parametric model, under suitable censorship assumptions, is the following\n",
    "\n",
    "$$\n",
    "\\mathscr{L}(\\alpha, \\beta; \\textbf{t},\\textbf{d}) \\propto \\prod_{i=1}^n h(t_i \\mid \\alpha, \\beta)^{d_i} S(t_i \\mid \\alpha, \\beta) = \\prod_{i : d_i=1}f(t_i \\mid \\alpha, \\beta) \\prod_{i: d_i = 0}S(t_i \\mid \\alpha,\\beta),\n",
    "$$\n",
    "because $f(t \\mid \\alpha, \\beta) = h(t\\mid \\alpha,\\beta)S(t \\mid \\alpha, \\beta)$. \n",
    "\n",
    "#### Inaccurate implementation\n",
    "\n",
    "The above likelihood can be **naively** implemented in **R** as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Koq4IidOhVq"
   },
   "outputs": [],
   "source": [
    "loglik_inaccurate <- function(t, d, alpha, beta) {\n",
    "  hazard <- prod((alpha / beta * (t / beta)^(alpha - 1))^d)\n",
    "  survival <- prod(exp(-(t / beta)^alpha))\n",
    "  log(hazard * survival)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9ebIm86OhVq"
   },
   "source": [
    "The log-likelihood is written in terms of products, which are numerically very unstable. Note for example that we may get `-Inf`, which is due to numerical inaccuracies. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "diFvA14sOhVr",
    "outputId": "3500abc2-da8e-48cf-c666-b3ce86e2a9d0"
   },
   "outputs": [],
   "source": [
    "loglik_inaccurate(t, d, alpha = 0.5, beta = 1000) # As it will be clear later on, these are likely values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKZgxo_GOhVr"
   },
   "source": [
    "#### Inefficient implementations\n",
    "\n",
    "The following two implementation are instead numerically stable but not efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwtdbSP-OhVs"
   },
   "outputs": [],
   "source": [
    "# 1st inefficient implementation\n",
    "loglik_inefficient1 <- function(t, d, alpha, beta) {\n",
    "  n <- length(t) # Sample size\n",
    "  log_hazards <- numeric(n)\n",
    "  log_survivals <- numeric(n)\n",
    "\n",
    "  for (i in 1:n) {\n",
    "    log_hazards[i] <- d[i] * ((alpha - 1) * log(t[i] / beta) + log(alpha / beta))\n",
    "    log_survivals[i] <- -(t[i] / beta)^alpha\n",
    "  }\n",
    "  sum(log_hazards) + sum(log_survivals)\n",
    "}\n",
    "\n",
    "# 2nd inefficient implementation\n",
    "loglik_inefficient2 <- function(t, d, alpha, beta) {\n",
    "  n <- length(t) # Sample size\n",
    "  log_hazards <- NULL\n",
    "  log_survivals <- NULL\n",
    "\n",
    "  for (i in 1:n) {\n",
    "    log_hazards <- c(log_hazards, d[i] * ((alpha - 1) * log(t[i] / beta) + log(alpha / beta)))\n",
    "    log_survivals <- c(log_survivals, -(t[i] / beta)^alpha)\n",
    "  }\n",
    "  sum(log_hazards) + sum(log_survivals)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXqO9LqKOhVs"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "0FDEoHsEOhVt",
    "outputId": "0e5a3dc1-0304-446a-b82b-d213ce550b6f"
   },
   "outputs": [],
   "source": [
    "loglik_inefficient1(t, d, alpha = 0.5, beta = 1000)\n",
    "loglik_inefficient2(t, d, alpha = 0.5, beta = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQhCQpXCOhVt"
   },
   "source": [
    "#### Accurate and efficient implementation\n",
    "\n",
    "The following implementation is instead numerically accurate and more efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "p97XWYoFOhVt",
    "outputId": "95aab775-4d16-427f-9797-ff6d0be12033"
   },
   "outputs": [],
   "source": [
    "# Efficient and numerically stable version\n",
    "loglik <- function(t, d, alpha, beta) {\n",
    "  log_hazard <- sum(d * ((alpha - 1) * log(t / beta) + log(alpha / beta)))\n",
    "  log_survival <- sum(-(t / beta)^alpha)\n",
    "  log_hazard + log_survival\n",
    "}\n",
    "\n",
    "loglik(t, d, alpha = 0.5, beta = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBEEhWrrOhVu"
   },
   "source": [
    "#### Benchmarking\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "69kJfVapOhVu",
    "outputId": "019b0490-13c6-4a8c-f792-75732121885b"
   },
   "outputs": [],
   "source": [
    "# install.packages(\"rbenchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "69kJfVapOhVu",
    "outputId": "019b0490-13c6-4a8c-f792-75732121885b"
   },
   "outputs": [],
   "source": [
    "library(rbenchmark) # Library for performing benchmarking\n",
    "\n",
    "benchmark(\n",
    "  loglik1 = loglik(t, d, alpha = 0.5, beta = 1000),\n",
    "  loglik2 = loglik_inefficient1(t, d, alpha = 0.5, beta = 1000),\n",
    "  loglik3 = loglik_inefficient2(t, d, alpha = 0.5, beta = 1000),\n",
    "  columns = c(\"test\", \"replications\", \"elapsed\", \"relative\"),\n",
    "  replications = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a37WzUCxOhVv"
   },
   "source": [
    "### Prior specification\n",
    "\n",
    "Within the Bayesian framework, we need to specify also prior distributions. Since the focus of the course is on **computations** we will not explore the sensitivity to the prior and we present a single \"reasonable\" choice. Note that both $\\alpha,\\beta$ are strictly positive, therefore we could choose\n",
    "\n",
    "$$\n",
    "\\theta_1 = \\log{\\alpha} \\sim \\text{N}(0,100), \\qquad \\theta_2 = \\log(\\beta) \\sim \\text{N}(0,100).\n",
    "$$\n",
    "\n",
    "Hence, in **R** we can define the log-prior and the log-posterior in terms of the transformed parameters $\\theta = (\\theta_1, \\theta_2)$ as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c583lVqpOhVv"
   },
   "outputs": [],
   "source": [
    "logprior <- function(theta) {\n",
    "  sum(dnorm(theta, 0, sqrt(100), log = TRUE))\n",
    "}\n",
    "\n",
    "logpost <- function(t, d, theta) {\n",
    "  loglik(t, d, exp(theta[1]), exp(theta[2])) + logprior(theta)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDarZyPyOhVw"
   },
   "source": [
    "## Metropolis-Hastings\n",
    "\n",
    "We aim at obtainins (possibly correlated) samples from the posterior distribution\n",
    "\n",
    "$$\n",
    "f(\\theta_1,\\theta_2 \\mid \\textbf{t},\\textbf{d}) \\propto \\mathscr{L}(\\theta_1, \\theta_2; \\textbf{t},\\textbf{d})f(\\theta_1)f(\\theta_2),\n",
    "$$\n",
    "recalling that $\\theta_1 = \\log{\\alpha}$ and $\\theta_2 = \\log{\\beta}$. This can be done using a random walk Metropolis-Hastings algorithm.\n",
    "\n",
    "The algorithm we described is implemented in R in the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcAOnvMPOhVw"
   },
   "outputs": [],
   "source": [
    "# R represent the number of samples\n",
    "# burn_in is the number of discarded samples\n",
    "RMH <- function(R, burn_in, t, d) {\n",
    "  out <- matrix(0, R, 2) # Initialize an empty matrix to store the values\n",
    "  theta <- c(0, 0) # Initial values\n",
    "  logp <- logpost(t, d, theta) # Log-posterior\n",
    "\n",
    "  for (r in 1:(burn_in + R)) {\n",
    "    theta_new <- rnorm(2, mean = theta, sd = 0.25) # Propose a new value\n",
    "    logp_new <- logpost(t, d, theta_new)\n",
    "    alpha <- min(1, exp(logp_new - logp))\n",
    "    if (runif(1) < alpha) {\n",
    "      theta <- theta_new # Accept the value\n",
    "      logp <- logp_new\n",
    "    }\n",
    "    # Store the values after the burn-in period\n",
    "    if (r > burn_in) {\n",
    "      out[r - burn_in, ] <- theta\n",
    "    }\n",
    "  }\n",
    "  out\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRlEqEZKOhVx"
   },
   "source": [
    "We can now run the algorithm. We choose `R = 50000` and `burn_in = 5000`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGm-cJ5ZOhVx"
   },
   "outputs": [],
   "source": [
    "R <- 50000\n",
    "burn_in <- 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07FUem67OhVy",
    "outputId": "246f8083-a03f-4a19-b537-8c2639d21711"
   },
   "outputs": [],
   "source": [
    "# install.packages(\"tictoc\");\n",
    "# install.packages(\"coda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEHxLQZhZSJQ",
    "outputId": "1c10b5b5-35c1-488b-e933-6275677187ed"
   },
   "outputs": [],
   "source": [
    "library(tictoc) # Library for \"timing\" the functions\n",
    "set.seed(123)\n",
    "\n",
    "tic()\n",
    "fit_MCMC <- RMH(R, burn_in, t, d)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSH33iI0OhVy"
   },
   "source": [
    "## Analysis of the results\n",
    "\n",
    "### Checking the convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "EkgWE04SOhVy",
    "outputId": "acc5f0c9-3851-4e92-b5b0-06e0b8c4bcc2"
   },
   "outputs": [],
   "source": [
    "library(coda)\n",
    "fit_MCMC <- exp(fit_MCMC) # Back to the original parametrization\n",
    "fit_MCMC <- as.mcmc(fit_MCMC) # Convert the matrix into a \"coda\" object\n",
    "plot(fit_MCMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1zvUXL8OhVz"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "9nJJD84KOhVz",
    "outputId": "e45f91b1-67ec-4850-d783-6e2dccecf919"
   },
   "outputs": [],
   "source": [
    "effectiveSize(fit_MCMC) # Effective sample size\n",
    "1 - rejectionRate(fit_MCMC) # Acceptance rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VWlKc_YOhVz"
   },
   "source": [
    "### Estimation of the survival curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yeohty6ZOhV0"
   },
   "outputs": [],
   "source": [
    "# Grid of values on which the survival function is computed\n",
    "grid <- seq(0, 3700, length = 50)\n",
    "\n",
    "# Initialized the empy vectors\n",
    "S_mean <- numeric(length(grid))\n",
    "S_upper <- numeric(length(grid))\n",
    "S_lower <- numeric(length(grid))\n",
    "\n",
    "for (i in 1:length(grid)) {\n",
    "  S_mean[i] <- mean(pweibull(grid[i], shape = fit_MCMC[, 1], fit_MCMC[, 2], lower.tail = FALSE))\n",
    "  S_lower[i] <- quantile(pweibull(grid[i], shape = fit_MCMC[, 1], fit_MCMC[, 2], lower.tail = FALSE), 0.025)\n",
    "  S_upper[i] <- quantile(pweibull(grid[i], shape = fit_MCMC[, 1], fit_MCMC[, 2], lower.tail = FALSE), 0.975)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9cF_t_6OhV0"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "ew7IVoZhOhV0",
    "outputId": "c24eeb8e-2bda-4d53-d6e1-d12f5eb6f664"
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "data_plot <- data.frame(Time = grid, Mean = S_mean, Upper = S_upper, Lower = S_lower)\n",
    "ggplot(data = data_plot, aes(x = Time, y = Mean, ymin = Lower, ymax = Upper)) +\n",
    "  geom_line() +\n",
    "  theme_bw() +\n",
    "  ylab(\"Survival function\") +\n",
    "  ylim(c(0, 1)) +\n",
    "  geom_ribbon(alpha = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "colab": {
   "collapsed_sections": [],
   "name": "un_A1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
